{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project2-models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPfWA02M5IIDl/16KeLtv2/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ypL0P4mHWCoN","executionInfo":{"status":"ok","timestamp":1617334018772,"user_tz":240,"elapsed":2319,"user":{"displayName":"Pranay Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrNIsg25NhXNk17bZ4ITnxg-LblC_LOkZ_XJqMcA=s64","userId":"06170843209587046729"}}},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n","from keras.metrics import MeanSquaredError\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.layers.experimental import preprocessing\n","from collections import Counter\n","\n","def build_model(features, norm, regularizer=None, n = 0, eta = 0.001,):\n","  \"\"\"\n","  Returns the build function for a neural network with n layers\n","  \n","  Keyword Arguments:\n","  features - the numer of features, used to define the input dimension for layers\n","  norm - normalization layer that can be added to normalize the data\n","  n - the number of hidden layers to use\n","  eta - learning rate for the optimizer\n","  \"\"\"\n","  model = Sequential()\n","\n","  if norm is not None:\n","    model.add(norm)\n","\n","  if n == 2:\n","    model.add(Dense(2 * features, input_dim = features, kernel_initializer = \"normal\", activation='relu', kernel_regularizer=regularizer))\n","\n","  if n >= 1:\n","    model.add(Dense(features, kernel_initializer = \"normal\", activation='relu', kernel_regularizer=regularizer))\n","\n","  model.add(Dense(1, kernel_initializer = \"normal\", kernel_regularizer=regularizer))\n","\n","  opt = keras.optimizers.Adam(learning_rate=eta)\n","  model.compile(loss='mean_squared_error', optimizer=opt, metrics=[])\n","\n","  return model\n","\n","\n","def rSq(x, y, layers, reg):\n","  \"\"\"Calculates the r squared of the given model\n","  \n","  x - the features in the data\n","  y - target data\n","  layers - neural net hidden layer number\n","  reg - the regularizer to use, l1 or l2\n","  \"\"\"\n","  normalizer = preprocessing.Normalization(input_shape=[x.shape[1],])\n","  normalizer.adapt(x)\n","  model = build_model(x.shape[1], None, reg, layers)\n","  model.fit(x, y, epochs = 100, batch_size = 5, verbose = 0)\n","\n","  y_hat = model.predict(x)\n","  mse = MeanSquaredError()\n","  sst = mse(y, np.mean(y)).numpy()\n","  mse = MeanSquaredError()\n","  sse = mse(y, y_hat).numpy()\n","  return (1 - (sse/sst))\n","\n","def rSq_adj(x, y, layers, reg):\n","  \"\"\"Calculates the adjusted r squared of the given model\n","  \n","  x - the features in the data\n","  y - target data\n","  layers - neural net hidden layer number\n","  reg - the regularizer to use, l1 or l2\"\"\"\n","  normalizer = preprocessing.Normalization(input_shape=[x.shape[1],])\n","  normalizer.adapt(x)\n","  model = build_model(x.shape[1], None, reg, layers)\n","  model.fit(x, y, epochs = 100, batch_size = 5, verbose = 0)\n","  rsq = rSq(x, y, layers, reg)\n","  top = (1 - rsq) * (len(y) - 1)\n","  bottom = (len(y) - model.count_params() - 1)\n","  return (1 - (top/bottom))\n","\n","def rSq_cv(x, y, layers, reg):\n","  \"\"\"Calculates the cross validated r squared of the given model\n","  \n","  x - the features in the data\n","  y - target data\n","  layers - neural net hidden layer number\n","  reg - the regularizer to use, l1 or l2\"\"\"\n","  regressor = KerasRegressor(build_fn = build_model, features=x.shape[1], norm=None, regularizer=None, n=layers, epochs = 100, batch_size = 5, verbose = 0)\n","  kfold = KFold(n_splits = 10)\n","  mse = MeanSquaredError()\n","  sst = mse(y, np.mean(y)).numpy()\n","  sse = np.mean(np.abs(cross_val_score(regressor, x, y, cv = kfold)))\n","  return (1 - (sse/sst))\n","\n","def AIC(x, y, layers, reg):\n","  \"\"\"Computes and returns the aic for a trained model.\n","  \n","  x - the features in the data\n","  y - target data\n","  layers - neural net hidden layer number\n","  reg - the regularizer to use, l1 or l2\"\"\"\n","  normalizer = preprocessing.Normalization(input_shape=[x.shape[1],])\n","  normalizer.adapt(x)\n","  model = build_model(x.shape[1], None, reg, layers)\n","  model.fit(x, y, epochs = 100, batch_size = 5, verbose = 0)\n","  y_hat = model.predict(x)\n","  mse = MeanSquaredError()\n","  sse = mse(y, y_hat).numpy()\n","  aic = len(y)*np.log(sse) + 2*model.count_params()\n","  return aic\n","\n","\n","def metric(x, y, layers, reg, criteria):\n","  \"\"\"Returns a metric value for a specific Neural Net based on layers and given criteria\n","  \n","  x - the features in the data\n","  y - target data\n","  layers - neural net hidden layer number\n","  reg - the regularizer to use, l1 or l2\n","  criteria - a metric to measure for a model, options are rsq, rsq_adj, rsq_cv, aic\n","  \"\"\"\n","  if criteria == \"rsq\":\n","    return rSq(x, y, layers, reg)\n","  elif criteria == \"rsq_adj\":\n","    return rSq_adj(x, y, layers, reg)\n","  elif criteria == \"rsq_cv\":\n","    return rSq_cv(x, y, layers, reg)\n","  elif criteria == \"aic\":\n","    return AIC(x, y, layers, reg)\n","\n","def forwardSel(layers, included, x, y, criteria):\n","  \"\"\"\n","  Chooses the next best feature to include in the model based on the given criteria\n","\n","  layers - neural net hidden layer number\n","  included - the features from x that have already been included in the model\n","  x - the features in the data\n","  y - target data\n","  criteria - the metric used to measure the model\n","  \"\"\"\n","  base_x = x[included]\n","  best = metric(base_x.values, y.values, layers, None, criteria) # make starting model\n","    \n","  # Features yet to be included\n","  remaining = x.columns.tolist()\n","  for i in included:\n","    remaining.remove(i)\n","\n","  new = included.copy()\n","        \n","  for i in remaining:\n","            \n","    using = included.copy()\n","\n","    using.append(i)\n","            \n","    temp_x = x[using]\n","    new_metric = metric(temp_x.values, y.values, layers, None, criteria)\n","        \n","    # If new model with added feature is better than base, then add features to new list.\n","    # If metric is rsq based, then check if its greater\n","    if criteria.startswith('rsq'):\n","      if new_metric > best:\n","        print(using, best, new_metric)\n","        best = new_metric\n","        new = using\n","    # If metric is aic then check if its lesser\n","    elif critera == 'aic':\n","      if new_metric < best:\n","        print(\"aic \", best, new_metric)\n","        best = new_metric\n","        new = using\n","\n","  temp_x = x[new]\n","  rsq = metric(temp_x.values,y.values,layers, None,'rsq')\n","  rsq_adj = metric(temp_x.values,y.values,layers, None,'rsq_adj')\n","  rsq_cv = metric(temp_x.values,y.values,layers, None,'rsq_cv')\n","  aic = metric(temp_x.values,y.values,layers, None, 'aic')\n","\n","  return new, rsq, rsq_adj, rsq_cv, aic\n","\n","def forwardSelAll(layers, data, response, metric):\n","  \"\"\"\n","  Chooses the the best combination of features from the dataset using forward selection\n","\n","  layers - neural net hidden layer number\n","  data - the entire dataset \n","  response - the response variable in the dataset\n","  criteria - the metric used to measure the model\n","  \"\"\"\n","  included = [] # The predictors used in the model\n","  \n","  # All four metrics which can be used to evaluate the model\n","  rsq = []\n","  rsq_adj = []\n","  rsq_cv = []\n","  aic = []\n","  num_features = []\n","\n","  x = data.drop(response, axis=1)\n","  y = data[response]\n","  for i in range(x.shape[1]):\n","\n","    new_features, new_rsq, new_rsq_adj, new_rsq_cv, new_aic = forwardSel(layers, included, x, y, metric)\n","\n","    rsq.append(new_rsq)\n","    rsq_adj.append(new_rsq_adj)\n","    rsq_cv.append(new_rsq_cv)\n","    aic.append(new_aic)\n","    num_features.append(len(new_features))\n","\n","    included = new_features\n","\n","  return included, rsq, rsq_adj, rsq_cv, aic, num_features\n","\n","def backwardElim(layers, included, x, y, criteria):\n","  \"\"\"\n","  Removes the worst feature in the model based on the given criteria\n","\n","  layers - neural net hidden layer number\n","  included - the features from x that are included in the model\n","  x - the features in the data\n","  y - target data\n","  criteria - the metric used to measure the model\n","  \"\"\"\n","  base_x = x[included]\n","  best = metric(base_x.values, y.values, layers, None, criteria) # make starting model\n","\n","  new = included.copy()\n","    \n","  if len(included) > 0:\n","            \n","    for i in included:\n","      using = included.copy()\n","      using.remove(i)\n","                \n","      temp_x = x[using] \n","      new_metric = 0       \n","      if len(using) > 0:\n","        new_metric = metric(temp_x.values, y.values, layers, None, criteria)\n","                \n","      # If new model with added feature is better than base, then add features to new list.\n","      # If metric is rsq based, then check if its greater\n","      if criteria.startswith('rsq'):\n","        if new_metric > best:\n","          print(using, best, new_metric)\n","          best = new_metric\n","          new = using\n","      # If metric is aic then check if its lesser\n","      elif critera == 'aic':\n","        if new_metric < best:\n","          print(\"aic \", best, new_metric)\n","          best = new_metric\n","          new = using\n","\n","  temp_x = x[new]\n","  rsq = metric(temp_x.values,y.values,layers, None,'rsq')\n","  rsq_adj = metric(temp_x.values,y.values,layers, None,'rsq_adj')\n","  rsq_cv = metric(temp_x.values,y.values,layers, None,'rsq_cv')\n","  aic = metric(temp_x.values,y.values,layers, None,'aic')\n","            \n","  return new, rsq, rsq_adj, rsq_cv, aic\n","\n","def backwardElimAll(layers, data, response, metric):\n","  \"\"\"\n","  Chooses the the best combination of features from the dataset using backward elimination\n","\n","  layers - neural net hidden layer number\n","  data - the entire dataset \n","  response - the response variable in the dataset\n","  criteria - the metric used to measure the model\n","  \"\"\"\n","  # Start will all features\n","  included = data.columns.tolist()\n","  included.remove(response)\n","\n","  rsq = []\n","  rsq_adj = []\n","  rsq_cv = []\n","  aic = []\n","  num_features = []\n","    \n","  x = data[included]\n","  y = data[response]\n","    \n","  for i in range(x.shape[1]):\n","       \n","    new_features, new_rsq, new_rsq_adj, new_rsq_cv, new_aic = backwardElim(layers, included, x, y, metric)\n","\n","    if Counter(new_features) != Counter(included):\n","      rsq.append(new_rsq)\n","      rsq_adj.append(new_rsq_adj)\n","      rsq_cv.append(new_rsq_cv)\n","      aic.append(new_aic)\n","      num_features.append(len(new_features))\n","        \n","      included = new_features\n","\n","  return included, rsq, rsq_adj, rsq_cv, aic, num_features\n","\n","def stepwiseReg(layers, included, x, y, criteria):\n","  \"\"\"\n","  Either adds the best not included feature or removes the worst included feature in the model based on the given criteria\n","\n","  layers - neural net hidden layer number\n","  included - the features from x that are included in the model\n","  x - the features in the data\n","  y - target data\n","  criteria - the metric used to measure the model\n","  \"\"\"\n","  base_x = x[included]\n","  best = metric(base_x.values, y.values, layers, None, criteria)\n","  rsq = metric(base_x.values, y.values, layers, None, 'rsq')\n","  rsq_adj = metric(base_x.values, y.values, layers, None, 'rsq_adj')\n","  rsq_cv = metric(base_x.values, y.values, layers, None, 'rsq_cv')\n","  aic = metric(base_x.values, y.values, layers, None, 'aic')\n","   \n","  final = included\n","\n","  forward, new_rsq, new_rsq_adj, new_rsq_cv, new_aic = forwardSel(layers, included, x, y, criteria)\n","  if new_rsq_adj > best:\n","    print(forward, best, new_rsq_adj)\n","    final = forward\n","    best = new_rsq_adj\n","    rsq, rsq_adj, rsq_cv, aic = new_rsq, new_rsq_adj, new_rsq_cv, new_aic\n","    \n","  backward, new_rsq, new_rsq_adj, new_rsq_cv, new_aic = backwardElim(layers, included, x, y, criteria)\n","  if new_rsq_adj > best:\n","    print(backward, best, new_rsq_adj)\n","    final = backward\n","    best = new_rsq_adj\n","    rsq, rsq_adj, rsq_cv, aic = new_rsq, new_rsq_adj, new_rsq_cv, new_aic\n","   \n","  return final, rsq, rsq_adj, rsq_cv, aic\n","\n","def stepwiseRegAll(layers, data, response, metric):\n","  \"\"\"\n","  Chooses the the best combination of features from the dataset using stepwise regression\n","\n","  layers - neural net hidden layer number\n","  data - the entire dataset \n","  response - the response variable in the dataset\n","  criteria - the metric used to measure the model\n","  \"\"\"\n","  included = []\n","  base_metric = 0\n","\n","  rsq = []\n","  rsq_adj = []\n","  rsq_cv = []\n","  aic = []\n","  num_features = []\n","\n","  x = data.drop(response, axis=1)\n","  y = data[response]\n","    \n","  while True:\n","        \n","    new_features, new_rsq, new_rsq_adj, new_rsq_cv, new_aic = stepwiseReg(layers, included, x, y, metric)\n","        \n","    rsq.append(new_rsq)\n","    rsq_adj.append(new_rsq_adj)\n","    rsq_cv.append(new_rsq_cv)\n","    aic.append(new_aic)\n","    num_features.append(len(new_features))\n","        \n","    included = new_features\n","\n","    if new_rsq_adj > base_metric:\n","      included = new_features\n","      base_metric = new_rsq_adj\n","    else:\n","      break\n","\n","  return included, rsq, rsq_adj, rsq_cv, aic, num_features\n","\n","def Regularizer(reg, layers, data, response):\n","  \"\"\"\n","  Chooses which regularizer to run the model with\n","\n","  reg - the regularizer to use, l1 or l2\n","  layers - neural net hidden layer number\n","  data - the entire dataset \n","  response - the response variable in the dataset\n","  \"\"\"\n","  x = data.drop(response, axis=1)\n","  y = data[response]\n","  rsq = metric(x.values,y,layers,reg,'rsq')\n","  rsq_adj = metric(x.values,y,layers,reg,'rsq_adj')\n","  rsq_cv = metric(x.values,y,layers,reg,'rsq_cv')\n","  aic = metric(x.values,y,layers,reg,'aic')\n","\n","  return rsq, rsq_adj, rsq_cv, aic\n","\n","\n","def feature_selection(layers, selection, data, response, metric):\n","  \"\"\"\n","  Chooses which feature selection method to run based on selection parameter\n","\n","  layers - neural net hidden layer number\n","  selection - the feature selection to use, options are foward, backward, stepwise\n","  data - the entire dataset \n","  response - the response variable in the dataset\n","  criteria - the metric used to measure the model\n","  \"\"\"\n","  if selection == 'forward':\n","    return forwardSelAll(layers, data, response, metric)\n","  elif selection == 'backward':\n","    return backwardElimAll(layers, data, response, metric)\n","  elif selection == 'stepwise':\n","    return stepwiseRegAll(layers, data, response, metric)\n","\n","def plotModel(rsq, rsq_adj, rsq_cv, aic, num, selection):\n","  \"\"\"\n","  Plots the various metrics of a model after feature selection\n","\n","  rsq - the r squared values of the model after going through feature selection\n","  rsq_adj - the adjusted r squared values of the model after going through feature selection\n","  rsq_cv - the cross validated r squared values of the model after going through feature selection\n","  aic - the AIC values of the model after going through feature selection\n","  num - the number of features at each step of feature selection\n","  selection - the feature selection method used\n","  \"\"\"\n","  plt.style.use(\"seaborn-bright\")\n","  metrics = pd.DataFrame(data = {'R-Squared': rsq, 'R-Squared_Adj': rsq_adj, 'R-Squared_CV': rsq_cv}, index = num)\n","  plt.figure()\n","  r = metrics.plot(xlabel='Number of Features', ylabel='R^2', figsize=(10,8))\n","  if selection == 'backward':\n","    plt.gca().invert_xaxis()\n","\n","  aic_df = pd.DataFrame(data = {'AIC': aic}, index = num)\n","  plt.figure()\n","  a = aic_df.plot(xlabel='Number of Features', ylabel='AIC', figsize=(10,8))\n","  if selection == 'backward':\n","    plt.gca().invert_xaxis()\n","  plt.show()\n","    \n","def runAllModels(data, response):\n","  \"\"\"\n","  Runs every specified model for a dataset. Can be customized to run whatever models are needed.\n","  By default, runs only forward selection for a perceptron.\n","\n","  data - the dataset to use\n","  response - target feature\n","  \"\"\"\n","  rsq = []\n","  rsq_adj = []\n","  rsq_cv = []\n","  aic = []\n","  print(data.name)\n","\n","  # Change list to run whichever types of neural net are wanted. \n","  # [0, 1, 2] 0 for perceptron, 1 for NN3L, 2 for NNXL. Change as needed\n","  for layer in [0]:\n","    if layer == 0:\n","      print(\"<---------------Perceptron-------------->\\n\")\n","    elif layer == 1:\n","      print(\"<---------------NeuralNet3L-------------->\\n\")\n","    elif layer == 2:\n","      print(\"<---------------NeuralNetXL-------------->\\n\")\n","    \n","    # Change list to run whichever types of feature selection methods are wanted. \n","    # ['forward', 'backward', 'stepwise']\n","    # forward for forward selection, backward for backward elimination, stepwise for stepwise regression\n","\n","    #for method in ['forward', 'backward', 'stepwise']:\n","    for method in ['forward']:\n","      if method == 'forward':\n","        print(\"<---------------Adjusted R-Squared based Forward Selection-------------->\\n\")\n","      elif method == 'backward':\n","        print(\"<---------------Adjusted R-Squared based Backward Elimination-------------->\\n\")\n","      elif method == 'stepwise':\n","       print(\"<---------------Adjusted R-Squared based Stepwise Regression-------------->\\n\")\n","\n","\n","      # This is the metric used to evaluate the models in the feature selection. Any of rsq,\n","      # rsq_adj, rsq_cv, and aic can be used instead. The default is rsq_adj since this is what we\n","      # found to be best.\n","      metric = \"rsq_adj\"\n","\n","      features, rsq, rsq_adj, rsq_cv, aic, num_features = feature_selection(layer, method, data, response, metric)\n","      print(features)\n","      plotModel(rsq, rsq_adj, rsq_cv, aic, num_features, method)\n","    \n","    # Change list to run either, both, or no regularization methods. \n","    # ['l1', 'l2'] l1 for L1 regularization and l2 for L2 regularization\n","    for regularizer in []:\n","      rsq, rsq_adj, rsq_cv, aic = Regularizer(regularizer, layer, data, response)\n","      if regularizer == 'l1':\n","        print(\"<---------------L1 Regularization-------------->\\n\")\n","      elif regularizer == 'l2':\n","        print(\"<---------------L2 Regularization-------------->\\n\")\n","\n","      print(\"R-Squared = \" + str(rsq) + \", Adjusted R-Squared = \" + str(rsq_adj) + \", R-Squared CV = \" + str(rsq_cv) + \", AIC = \" + str(aic) + \"\\n\")\n","      \n","\n","\n","\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyDXt5Wsm-7D"},"source":["url = 'https://raw.githubusercontent.com/Data-Science-II/Project2-PranayKumar-DylanFauntleroy-NathanHales/main/Datasets/auto-mpg.csv'\n","\n","autompg = pd.read_csv(url)\n","autompg = autompg.fillna(autompg.mean())\n","autompg.name = 'auto-mpg'\n","print(autompg.dtypes)\n","\n","runAllModels(autompg, 'mpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCYC236wSt1x"},"source":["url = 'https://raw.githubusercontent.com/Data-Science-II/Project2-PranayKumar-DylanFauntleroy-NathanHales/main/Datasets/Concrete_Data.csv'\n","\n","concrete = pd.read_csv(url)\n","concrete = concrete.fillna(concrete.mean())\n","concrete.name = 'concrete'\n","print(concrete.dtypes)\n","\n","runAllModels(concrete, 'Concrete compressive strength(MPa, megapascals) ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yR3prpF0UlBt"},"source":["url = 'https://raw.githubusercontent.com/Data-Science-II/Project2-PranayKumar-DylanFauntleroy-NathanHales/main/Datasets/Red_Wine_Quality.csv'\n","\n","wine = pd.read_csv(url)\n","wine = wine.fillna(wine.mean())\n","wine.name = 'wine'\n","print(wine.dtypes)\n","\n","runAllModels(wine, 'quality')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cPIlOJYVRtV"},"source":["url = 'https://raw.githubusercontent.com/Data-Science-II/Project2-PranayKumar-DylanFauntleroy-NathanHales/main/Datasets/SeoulBikeData.csv'\n","\n","bike = pd.read_csv(url)\n","bike = bike.fillna(bike.mean())\n","bike = bike.select_dtypes(exclude=['object'])\n","bike.name = 'bike'\n","print(bike.dtypes)\n","\n","runAllModels(bike, 'Rented Bike Count')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1V3G4bpah9g"},"source":["url = 'https://raw.githubusercontent.com/Data-Science-II/Project2-PranayKumar-DylanFauntleroy-NathanHales/main/Datasets/Data_for_UCI_named.csv'\n","\n","electric = pd.read_csv(url)\n","electric = electric.fillna(electric.mean())\n","electric.name = 'electric'\n","electric = electric.drop('stabf', axis=1)\n","print(electric.dtypes)\n","\n","runAllModels(electric, 'stab')"],"execution_count":null,"outputs":[]}]}